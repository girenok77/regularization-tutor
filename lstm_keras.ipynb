{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lstm-keras.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "MhQZmTWqQlPi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# LSTM in Keras\n",
        "Here we will create and train a LSTM-network with Keras and train it on a synthetic data. Each sequence in this generated data will consist of 5 time steps (`ROLLING_WINDOW`) each containig four features (`x1`..`x4`). Features will be chosen as random bits (0 or 1). The output (`y`) of each sequence will be one bit (0 or 1). It is XOR over the first feature (`x1`) in each sequence.\n",
        "![Sequence generation explanation](https://grez911.github.io/files/lstm_keras.png)"
      ]
    },
    {
      "metadata": {
        "id": "kbaw5ok8mDlV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Define global constants."
      ]
    },
    {
      "metadata": {
        "id": "e0GOwlxnpCRw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "LSTM_UNITS = 10     # Size of the LSTM memory.\n",
        "BATCH_SIZE = 2**10  # Mini-batch size.\n",
        "ROLLING_WINDOW = 5  # Each sequence will contain 5 time steps.\n",
        "TRAIN_SIZE = 2**20  # Number of training examples.\n",
        "TEST_SIZE = 2**12   # Number of testing examples."
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MGPTpk0BmHvU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Make imports."
      ]
    },
    {
      "metadata": {
        "id": "47AuXePTo2-s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3247a4e4-bcbd-4de7-d877-49c1a867b505"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "MbO2Z9t9mKxL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Define auxilary functions."
      ]
    },
    {
      "metadata": {
        "id": "tuBMsa_dhMVp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def xor(array):\n",
        "  '''\n",
        "  Calculates XOR of an array.\n",
        "  \n",
        "  Examples:\n",
        "  [0, 1] -> 1\n",
        "  [1, 1] -> 0\n",
        "  [0, 0, 0] -> 0\n",
        "  [0, 1, 1, 1] -> 1\n",
        "  \n",
        "  Inputs:\n",
        "  array - numpy array.\n",
        "  \n",
        "  Outputs:\n",
        "  XOR function.\n",
        "  '''\n",
        "  for i in range(len(array)):\n",
        "    if i == 0:\n",
        "      res = np.logical_xor(0, array[i])\n",
        "    else:\n",
        "      res = np.logical_xor(res, array[i])\n",
        "  return int(res)    "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6ZeARrycM5Lv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def batch_gen(data, bs):\n",
        "  '''\n",
        "  Batch generator. It produces only full-sized batches.\n",
        "  If the data can not be divided evenly into batches then\n",
        "  the remaining is just ignored.\n",
        "  \n",
        "  Inputs:\n",
        "  data - numpy array containing X and y.\n",
        "  bs - batch size.\n",
        "  \n",
        "  Outputs the next batch each time.\n",
        "  '''\n",
        "  i = 0\n",
        "  while True:\n",
        "    X = []\n",
        "    y = []\n",
        "    for j in range(bs):\n",
        "      matrix = data[i*bs+j:i*bs+j+ROLLING_WINDOW]\n",
        "      X_timestep = matrix[:, :-1]\n",
        "      y_timestep = matrix[-1, -1]\n",
        "      X.append(X_timestep)\n",
        "      y.append(y_timestep)\n",
        "    if i >= steps_per_epoch(len(data))-1:\n",
        "      i = 0\n",
        "    else:\n",
        "      i += 1\n",
        "    yield (np.array(X), np.array(y))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ym1JE2bQKffE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def gen_data(length):\n",
        "  '''\n",
        "  Generate data with four features and a binary output. Input features (x1..x4)\n",
        "  are random bits (0 or 1). Outpus (y) is a XOR function over x1 feature each\n",
        "  timestep in the sequence.\n",
        "  \n",
        "  Inputs:\n",
        "  length - number of training examples.\n",
        "  \n",
        "  Outputs:\n",
        "  df - dataframe with created data.\n",
        "  '''\n",
        "  df = pd.DataFrame(np.random.randint(2, size=(length, 4)), columns=['x1', 'x2', 'x3', 'x4'])\n",
        "  df['y'] = df['x1'].rolling(ROLLING_WINDOW).apply(xor)\n",
        "  return df"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4edQluPq8iqs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def steps_per_epoch(data_length):\n",
        "  '''\n",
        "  Calculate how many mini-batches will be in the data.\n",
        "  \n",
        "  Inputs:\n",
        "  data_length - overal length of the data.\n",
        "  \n",
        "  Outputs number of mini-batches.\n",
        "  '''\n",
        "  return int((data_length - ROLLING_WINDOW + 1) / BATCH_SIZE)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JK916UJ7mOzi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Create a train dataset."
      ]
    },
    {
      "metadata": {
        "id": "EYX2Lx5OeXmf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        },
        "outputId": "b7701875-4a78-4586-a564-fa40ec70e43a"
      },
      "cell_type": "code",
      "source": [
        "train_df = gen_data(TRAIN_SIZE)\n",
        "train_df.head(16)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>x1</th>\n",
              "      <th>x2</th>\n",
              "      <th>x3</th>\n",
              "      <th>x4</th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    x1  x2  x3  x4    y\n",
              "0    0   0   0   1  NaN\n",
              "1    1   1   1   1  NaN\n",
              "2    1   1   0   1  NaN\n",
              "3    1   1   0   0  NaN\n",
              "4    0   1   0   0  1.0\n",
              "5    1   1   0   1  0.0\n",
              "6    0   1   0   1  1.0\n",
              "7    0   1   0   0  0.0\n",
              "8    0   0   1   0  1.0\n",
              "9    1   1   1   0  0.0\n",
              "10   0   1   1   0  1.0\n",
              "11   1   1   0   0  0.0\n",
              "12   0   1   1   1  0.0\n",
              "13   0   1   1   0  0.0\n",
              "14   0   0   0   0  1.0\n",
              "15   1   1   1   0  0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "JbVWMmZlmTTD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Convert the data to a numpy array to increase the speed of a batch generation."
      ]
    },
    {
      "metadata": {
        "id": "WuJ_qOkIIiMy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "0bbcfd57-f860-4e81-f2fb-c4458bae0176"
      },
      "cell_type": "code",
      "source": [
        "train_data = train_df.as_matrix()\n",
        "train_data"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.,  0.,  0.,  1., nan],\n",
              "       [ 1.,  1.,  1.,  1., nan],\n",
              "       [ 1.,  1.,  0.,  1., nan],\n",
              "       ...,\n",
              "       [ 0.,  1.,  1.,  1.,  0.],\n",
              "       [ 0.,  0.,  1.,  0.,  1.],\n",
              "       [ 1.,  1.,  0.,  1.,  1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "Q-YsON8ymVSq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Create a LSTM network."
      ]
    },
    {
      "metadata": {
        "id": "E8Qoz9vyo8wA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "65b36fbb-0591-42db-8e90-72e7e8c027a8"
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(LSTM_UNITS, input_shape=(ROLLING_WINDOW, len(train_df.columns) - 1)))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['binary_accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_1 (LSTM)                (None, 10)                600       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 11        \n",
            "=================================================================\n",
            "Total params: 611\n",
            "Trainable params: 611\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "80l3JXaAmatX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Train it."
      ]
    },
    {
      "metadata": {
        "id": "Nc8M-oKnjIdD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 729
        },
        "outputId": "dd5fdee0-0fb9-4cfa-8432-e840c2709b68"
      },
      "cell_type": "code",
      "source": [
        "train_gen = batch_gen(train_data, BATCH_SIZE)\n",
        "model.fit_generator(train_gen, steps_per_epoch=steps_per_epoch(TRAIN_SIZE), epochs=20)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "1023/1023 [==============================] - 13s 12ms/step - loss: 0.6933 - binary_accuracy: 0.5004\n",
            "Epoch 2/20\n",
            "1023/1023 [==============================] - 11s 11ms/step - loss: 0.6932 - binary_accuracy: 0.5000\n",
            "Epoch 3/20\n",
            "1023/1023 [==============================] - 12s 11ms/step - loss: 0.6932 - binary_accuracy: 0.4999\n",
            "Epoch 4/20\n",
            "1023/1023 [==============================] - 12s 11ms/step - loss: 0.6932 - binary_accuracy: 0.5001\n",
            "Epoch 5/20\n",
            "1023/1023 [==============================] - 11s 11ms/step - loss: 0.6932 - binary_accuracy: 0.5001\n",
            "Epoch 6/20\n",
            "1023/1023 [==============================] - 12s 11ms/step - loss: 0.6932 - binary_accuracy: 0.5002\n",
            "Epoch 7/20\n",
            "1023/1023 [==============================] - 12s 11ms/step - loss: 0.6932 - binary_accuracy: 0.5002\n",
            "Epoch 8/20\n",
            "1023/1023 [==============================] - 12s 11ms/step - loss: 0.6932 - binary_accuracy: 0.5004\n",
            "Epoch 9/20\n",
            "1023/1023 [==============================] - 12s 11ms/step - loss: 0.6932 - binary_accuracy: 0.5006\n",
            "Epoch 10/20\n",
            "1023/1023 [==============================] - 12s 11ms/step - loss: 0.6932 - binary_accuracy: 0.5007\n",
            "Epoch 11/20\n",
            "1023/1023 [==============================] - 12s 11ms/step - loss: 0.6932 - binary_accuracy: 0.5009\n",
            "Epoch 12/20\n",
            "1023/1023 [==============================] - 12s 11ms/step - loss: 0.6595 - binary_accuracy: 0.5923\n",
            "Epoch 13/20\n",
            "1023/1023 [==============================] - 11s 11ms/step - loss: 0.1791 - binary_accuracy: 0.9714\n",
            "Epoch 14/20\n",
            "1023/1023 [==============================] - 12s 11ms/step - loss: 0.0183 - binary_accuracy: 1.0000\n",
            "Epoch 15/20\n",
            "1023/1023 [==============================] - 12s 11ms/step - loss: 0.0055 - binary_accuracy: 1.0000\n",
            "Epoch 16/20\n",
            "1023/1023 [==============================] - 12s 11ms/step - loss: 0.0023 - binary_accuracy: 1.0000\n",
            "Epoch 17/20\n",
            "1023/1023 [==============================] - 12s 11ms/step - loss: 0.0011 - binary_accuracy: 1.0000\n",
            "Epoch 18/20\n",
            "1023/1023 [==============================] - 12s 11ms/step - loss: 5.8271e-04 - binary_accuracy: 1.0000\n",
            "Epoch 19/20\n",
            "1023/1023 [==============================] - 12s 11ms/step - loss: 3.1587e-04 - binary_accuracy: 1.0000\n",
            "Epoch 20/20\n",
            "1023/1023 [==============================] - 12s 11ms/step - loss: 1.6578e-04 - binary_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f103ea3ceb8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "j5e_aTk0mdI9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Create a test dataset and measure the performance."
      ]
    },
    {
      "metadata": {
        "id": "cSWEWrD3jln4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "c6adb3bf-c8b4-44ef-f398-265c77ebc611"
      },
      "cell_type": "code",
      "source": [
        "test_data = gen_data(TEST_SIZE).as_matrix()\n",
        "test_gen = batch_gen(test_data, BATCH_SIZE)\n",
        "res = model.evaluate_generator(test_gen, steps=steps_per_epoch(TEST_SIZE))\n",
        "i = 0\n",
        "for m in model.metrics_names:\n",
        "  print(f\"{m}: {res[i]:.3f}\")\n",
        "  i += 1"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss: 0.000\n",
            "binary_accuracy: 1.000\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
